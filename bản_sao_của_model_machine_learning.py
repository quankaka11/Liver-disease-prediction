# -*- coding: utf-8 -*-
"""Bản sao của Model_machine_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfQ-7GhiZcnM6NT53p8niSwQK8e9qdCX

# Chạy mô hình dự đoán ưng thu bệnh gan
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Xử lý dữ liệu"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

data=pd.read_csv("/content/drive/MyDrive/indian_liver_patient.csv")
data.head()

data.info() #một số trường dữ liệu bị thiếu

data.isna().sum()

data['Albumin_and_Globulin_Ratio'].fillna(value=0, inplace=True)  #thay thế các giá trị thiếu bằng 0

"""### Gán bệnh nhân mắc bệnh là 1, không mắc bệnh là 0

"""

data['Dataset'] = data['Dataset'].map({2:0,1:1})

data['Dataset'].value_counts()

count_classes = pd.value_counts(data['Dataset'], sort = True).sort_index()
count_classes.plot(kind = 'bar')
plt.title("Liver disease classes histogram")
plt.xlabel("Dataset")
plt.ylabel("Frequency")

"""### Tạo bảng tóm tắt


"""

data.describe() #tạo bảng tóm tắt thống kê các thông số đặc trưng

"""### Tỉ lệ giới tính và mã hóa nó"""

import seaborn as sns
sns.countplot(data = data, x='Gender', label='count')

"""#### Mã hóa"""

def partition(x):
    if x == 'Male':
        return 1
    return 0

data['Gender'] = data['Gender'].map(partition)

data

"""### Chuyển cột data set thành các giá trị 0 và 1
#### '1' cho bệnh gan và '2' cho không có bệnh gan vì vậy hãy đặt nó thành 0 cho không có bệnh để thuận tiện
"""

# def partition(x):
#     if x == 2:
#         return 0
#     return 1

# data['Dataset'] = data['Dataset'].map(partition)

data['Dataset']

"""### Tạo biểu đồ headmap hiển thị sự tương quan tăng giảm giữa các đối tượng liên quan"""

plt.figure(figsize=(12,8))
plt.title('Biểu đồ nhiệt thể hiện sự tương quan giữa các thành phần')
sns.heatmap(data.corr(),linewidths=0.25,vmax=1.0, square=True, cmap="YlGnBu", linecolor='black',annot=True)
plt.show()

"""## Chạy mô hình

### Chia tập dữ liệu
"""

X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values #dataset

"""### Chia thành dữ liệu huấn luyện và kiểm tra

#### Sử dụng kĩ thuật feature scaling và smote (Tính mới)
##### Những mô hình thông thường chia dữ liệu 1 cách khá ngẫu nhiên dẫn đến nhiều dữ liệu bị chồng chéo giữa các lớp. Sử dụng kĩ thuật này trước khi chia dữ liệu giúp cải thiện hiệu suất của mô hình phân loại trên dữ liệu mất cân bằng.Thực hiện feature scaling trước (để chuẩn hóa các đặc trưng của dữ liệu), sau đó thực hiện SMOTE để xử lý mất cân bằng dữ liệu.

##### Smote - Xư lý mất cân bằng
![Công thức](https://drive.google.com/uc?export=view&id=1ZISaQtrjfz4zWlH6GZuTsT2Hw1xNfa-G)
"""

import numpy as np
from sklearn.neighbors import NearestNeighbors
from collections import Counter

def smote(X, y, minority_class): # để tăng cường lớp thiểu số
    # Tìm các mẫu thuộc lớp thiểu số
    X_minority = X[y == minority_class]

    # Số lượng mẫu cần tạo thêm
    n_minority_samples = X_minority.shape[0]
    n_neighbors = 5

    # Kết nối k láng giềng gần nhất
    neighbors = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(X_minority)
    indices = neighbors.kneighbors(X_minority, return_distance=False)[:, 1:]

    # Tạo các mẫu tổng hợp
    synthetic_samples = []
    for i in range(n_minority_samples):
        for _ in range(n_neighbors):
            nn = np.random.choice(indices[i])
            diff = X_minority[nn] - X_minority[i]
            synthetic_sample = X_minority[i] + np.random.rand() * diff
            synthetic_samples.append(synthetic_sample)

    # Chuyển đổi thành numpy array
    synthetic_samples = np.array(synthetic_samples)

    # Kết hợp với dữ liệu ban đầu
    X_resampled = np.vstack((X, synthetic_samples))
    y_resampled = np.hstack((y, np.full(synthetic_samples.shape[0], minority_class)))

    return X_resampled, y_resampled

def tomek_links(X, y): # loại bỏ các mẫu gây nhiễu
    from sklearn.neighbors import NearestNeighbors

    # Kết nối 1 láng giềng gần nhất
    nn = NearestNeighbors(n_neighbors=2).fit(X)
    distances, indices = nn.kneighbors(X)

    # Tìm Tomek links
    tomek_links = []
    for i in range(len(X)):
        if y[i] != y[indices[i][1]]:
            if indices[indices[i][1]][1] == i:
                tomek_links.append(i)

    # Xóa các mẫu Tomek links
    mask = np.ones(len(X), dtype=bool)
    mask[tomek_links] = False

    return X[mask], y[mask]

def smote_tomek(X, y):
    # Tìm lớp thiểu số
    counter = Counter(y)
    majority_class = max(counter, key=counter.get)
    minority_class = min(counter, key=counter.get)

    # Áp dụng SMOTE
    X_resampled, y_resampled = smote(X, y, minority_class)

    # Áp dụng Tomek links
    X_cleaned, y_cleaned = tomek_links(X_resampled, y_resampled)

    return X_cleaned, y_cleaned

X_smote, y_smote = smote_tomek(X, y)

"""##### Chia dữ liệu"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X_smote,y_smote, test_size=0.3, random_state=33)

"""##### Feature - Chuẩn hóa
![Công thức](https://drive.google.com/uc?export=view&id=1idPkdOEfTfCyrejmJYFeFyGsj5PpV7Zq)
"""

import numpy as np

def fit_transform_standard_scaler(x_train):
    means = np.mean(x_train, axis=0)
    stds = np.std(x_train, axis=0)
    x_train = (x_train - means) / stds
    return x_train, means, stds

# Hàm để chuẩn hóa tập kiểm tra sử dụng các thông số từ tập huấn luyện
def transform_standard_scaler(x_test, means, stds):
    x_test = (x_test - means) / stds
    return x_test

# Chuẩn hóa tập huấn luyện và tính toán mean và std
x_train, means, stds = fit_transform_standard_scaler(x_train)

# Chuẩn hóa tập kiểm tra sử dụng các thông số từ tập huấn luyện
x_test = transform_standard_scaler(x_test, means, stds)

"""### RandomForestClassifier"""

import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from imblearn.combine import SMOTETomek
from sklearn.preprocessing import StandardScaler
import joblib

# Giả sử bạn đã có dữ liệu X và y
# X = ...
# y = ...

# Áp dụng SMOTETomek
smote = SMOTETomek()
X_smote, y_smote = smote.fit_resample(X, y)

# Chia dữ liệu thành tập huấn luyện và tập kiểm tra
x_train, x_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=33)

# Chuẩn hóa dữ liệu
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

# Xây dựng mô hình Random Forest
RandomForest = RandomForestClassifier()
RandomForest = RandomForest.fit(x_train, y_train)

# Dự đoán nhãn trên tập kiểm tra
y_pred = RandomForest.predict(x_test)

# Tính chỉ số Accuracy và lưu lại
accuracy_rf = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy_rf)

# Lưu mô hình và scaler
joblib.dump(RandomForest, 'random_forest_model.pkl')
joblib.dump(sc, 'scaler.pkl')

# Tạo DataFrame để so sánh y_test và y_pred
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

# In ra DataFrame
print(comparison)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve,roc_auc_score

# Tính toán các giá trị cần thiết cho biểu đồ ROC
y_pred_proba = RandomForest.predict_proba(x_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Vẽ biểu đồ ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""##### Dự đoán từ đầu vào"""

import numpy as np
import joblib

# Load mô hình và scaler
model = joblib.load('random_forest_model.pkl')
scaler = joblib.load('scaler.pkl')

# Nhập các chỉ số từ người dùng
def get_user_input():
    feature_names = [
        "Age", "Gender", "Total_Bilirubin", "Direct_Bilirubin", "Alkaline_Phosphotase",
        "Alamine_Aminotransferase", "Aspartate_Aminotransferase", "Total_Protiens",
        "Albumin", "Albumin_and_Globulin_Ratio"
    ]
    user_input = []
    for feature in feature_names:
        value = float(input(f"Nhập giá trị cho {feature}: "))
        user_input.append(value)
    return np.array(user_input).reshape(1, -1)

# Nhận dữ liệu đầu vào từ người dùng
user_input = get_user_input()

# Chuẩn hóa dữ liệu đầu vào
user_input_scaled = scaler.transform(user_input)

# Dự đoán
prediction = model.predict(user_input_scaled)

# In kết quả
if prediction[0] == 1:
    print("Dự đoán: Mắc bệnh")
else:
    print("Dự đoán: Không mắc bệnh")

from sklearn.metrics import f1_score
f1_rf = f1_score(y_test, y_pred)

# In ra chỉ số F1-score
print('F1-score:', f1_rf)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import jaccard_score

# Xây dựng mô hình Random Forest
liverDisease_rf = RandomForestClassifier()

# Huấn luyện mô hình trên tập huấn luyện
liverDisease_rf.fit(x_train, y_train)

# Dự đoán nhãn trên tập kiểm tra
rf_yhat = liverDisease_rf.predict(x_test)

# Tính chỉ số Jaccard
rf_ja = jaccard_score(y_test, rf_yhat)

print("Jaccard:",rf_ja)

"""### KNN"""

from sklearn.metrics import accuracy_score, f1_score, jaccard_score
from sklearn.neighbors import KNeighborsClassifier

# Xây dựng mô hình KNN
knn = KNeighborsClassifier()
knn.fit(x_train, y_train)

# Dự đoán nhãn trên tập kiểm tra
y_pred_knn = knn.predict(x_test)

# Tính và lưu chỉ số Accuracy
accuracy_knn = accuracy_score(y_test, y_pred_knn)

# Tính và lưu chỉ số F1-score
f1_knn = f1_score(y_test, y_pred_knn)

# Tính và lưu chỉ số Jaccard
jaccard_knn = jaccard_score(y_test, y_pred_knn)

# In ra các chỉ số
print("Accuracy của KNN:", accuracy_knn)
print("F1-score của KNN:", f1_knn)
print("Jaccard score của KNN:", jaccard_knn)

"""### Decision Tree"""

from sklearn.metrics import accuracy_score, f1_score, jaccard_score
from sklearn.tree import DecisionTreeClassifier

# Xây dựng mô hình Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(x_train, y_train)

# Dự đoán nhãn trên tập kiểm tra
y_pred_dt = decision_tree.predict(x_test)

# Tính và lưu chỉ số Accuracy
accuracy_dt = accuracy_score(y_test, y_pred_dt)

# Tính và lưu chỉ số F1-score
f1_dt = f1_score(y_test, y_pred_dt)

# Tính và lưu chỉ số Jaccard
jaccard_dt = jaccard_score(y_test, y_pred_dt)

# In ra các chỉ số
print("Accuracy của Decision Tree:", accuracy_dt)
print("F1-score của Decision Tree:", f1_dt)
print("Jaccard score của Decision Tree:", jaccard_dt)

"""### LogisticRegression"""

from sklearn.metrics import accuracy_score, f1_score, jaccard_score
from sklearn.linear_model import LogisticRegression

# Xây dựng mô hình Logistic Regression
logistic_regression = LogisticRegression()
logistic_regression.fit(x_train, y_train)

# Dự đoán nhãn trên tập kiểm tra
y_pred_lr = logistic_regression.predict(x_test)

# Tính và lưu chỉ số Accuracy
accuracy_lr = accuracy_score(y_test, y_pred_lr)

# Tính và lưu chỉ số F1-score
f1_lr = f1_score(y_test, y_pred_lr)

# Tính và lưu chỉ số Jaccard
jaccard_lr = jaccard_score(y_test, y_pred_lr)

# In ra các chỉ số
print("Accuracy của Logistic Regression:", accuracy_lr)
print("F1-score của Logistic Regression:", f1_lr)
print("Jaccard score của Logistic Regression:", jaccard_lr)

"""### So sánh kết quả"""

# Khởi tạo các mô hình
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "KNN": KNeighborsClassifier(),
    "Random Forest": RandomForestClassifier()
}

# Khởi tạo dataframe để lưu kết quả
results = pd.DataFrame(columns=["Accuracy", "F1-score", "Jaccard"])

# Lặp qua từng mô hình để tính và lưu các chỉ số
for name, model in models.items():
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    jaccard = jaccard_score(y_test, y_pred)
    results.loc[name] = [accuracy, f1, jaccard]

# Vẽ bảng hiển thị kết quả
print("Kết quả:")
print(results)

"""Kết quả của nghiên cứu khác:

![Kết quả nghiên cứu khác](https://drive.google.com/uc?export=view&id=1ce3Q76NFiXZKb6pgGrD4d3Y8Ff-hLbCe)

- **Accuracy:** Đây là tỷ lệ phần trăm giữa số lượng dự đoán chính xác và tổng số dự đoán. Nó cho biết mức độ chính xác của mô hình trong việc dự đoán nhãn của các điểm dữ liệu.
- **F1-score:** Đây là một số đo kết hợp giữa độ chính xác (precision) và độ phủ (recall) của mô hình. Nó thường được sử dụng khi dữ liệu mất cân bằng và mức độ quan trọng của việc phân loại sai các lớp là khác nhau.
- **Jaccard:** Còn được gọi là chỉ số Jaccard, là một phép đo độ tương đồng giữa hai tập hợp, đo bằng tỷ lệ giữa kích thước tập hợp giao nhau và kích thước tập hợp hợp nhất của chúng. Trong ngữ cảnh phân loại, Jaccard score được sử dụng để đo sự tương đồng giữa tập hợp các nhãn dự đoán và tập hợp các nhãn thực tế của mô hình.
"""